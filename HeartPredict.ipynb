{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEART DISEASE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df = pd.read_csv(\"heart.csv\")\n",
    "# data = pd.read_csv(\"heart.csv\")\n",
    "heart_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heart_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartegorical_columns = [\"ChestPainType\",\"RestingECG\",\"ExerciseAngina\",\"ST_Slope\",\"HeartDisease\",\"FastingBS\"]\n",
    "for column in cartegorical_columns:\n",
    "    plt.figure()\n",
    "    heart_df[column].value_counts().plot(kind='bar')\n",
    "   \n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Number of Patients\")\n",
    "    plt.title(f\"{column}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\", \"HeartDisease\", \"FastingBS\"]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    plt.figure()\n",
    "    if column == \"ChestPainType\":\n",
    "        # Filter the data for patients with and without heart disease\n",
    "        chestpain_heart_disease = heart_df[heart_df[\"HeartDisease\"] == 1][column].value_counts()\n",
    "        chestpain_no_heart_disease = heart_df[heart_df[\"HeartDisease\"] == 0][column].value_counts()\n",
    "\n",
    "        # Get the unique ST slope values\n",
    "        chestpain_values = heart_df[column].unique()\n",
    "\n",
    "        # Get the counts for patients with heart disease and without heart disease\n",
    "        y_heart_disease = [chestpain_heart_disease.get(slope, 0) for slope in chestpain_values]\n",
    "        y_no_heart_disease = [chestpain_no_heart_disease.get(slope, 0) for slope in chestpain_values]\n",
    "\n",
    "        # Create the x-axis positions for the bars\n",
    "        x = range(len(chestpain_values))\n",
    "\n",
    "        # Plotting the bar chart for ST_Slope\n",
    "        width = 0.35\n",
    "        plt.bar(x, y_heart_disease, width, label=\"Heart Disease\")\n",
    "        plt.bar([val + width for val in x], y_no_heart_disease, width, label=\"No Heart Disease\")\n",
    "\n",
    "        # Set the x-axis ticks and labels\n",
    "        plt.xticks([val + width/2 for val in x], chestpain_values)\n",
    "\n",
    "    else:\n",
    "        # Plotting the bar chart for other columns\n",
    "        heart_df[column].value_counts().plot(kind='bar')\n",
    "\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Number of Patients\")\n",
    "    plt.title(f\"Comparison of {column} with Heart Disease\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gender_columns = [\"Sex\"]\n",
    "heart_disease_columns = [\"HeartDisease\"]\n",
    "\n",
    "for gender_column in gender_columns:\n",
    "    for heart_disease_column in heart_disease_columns:\n",
    "        plt.figure()\n",
    "        \n",
    "        # Filter the data for males with and without heart disease\n",
    "        males_with_heart_disease = heart_df[(heart_df[gender_column] == \"M\") & (heart_df[heart_disease_column] == 1)]\n",
    "        males_no_heart_disease = heart_df[(heart_df[gender_column] == \"M\") & (heart_df[heart_disease_column] == 0)]\n",
    "        \n",
    "        # Filter the data for females with and without heart disease\n",
    "        females_with_heart_disease = heart_df[(heart_df[gender_column] == \"F\") & (heart_df[heart_disease_column] == 1)]\n",
    "        females_no_heart_disease = heart_df[(heart_df[gender_column] == \"F\") & (heart_df[heart_disease_column] == 0)]\n",
    "        \n",
    "        # Count the number of males and females with and without heart disease\n",
    "        counts = [\n",
    "            len(males_with_heart_disease), len(females_with_heart_disease),\n",
    "            len(males_no_heart_disease), len(females_no_heart_disease)\n",
    "        ]\n",
    "        \n",
    "        # Labels for the x-axis\n",
    "        labels = ['Males (1)', 'Females (1)', 'Males (0)', 'Females (0)']\n",
    "        \n",
    "        # Plotting the bar chart\n",
    "        plt.bar(labels, counts)\n",
    "        \n",
    "        plt.xlabel('Gender and Heart Disease')\n",
    "        plt.ylabel('Number of Patients')\n",
    "        plt.title(f\"Comparison of Patients by Gender and Heart Disease\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\", \"HeartDisease\", \"FastingBS\"]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    plt.figure()\n",
    "    if column == \"ST_Slope\":\n",
    "        # Filter the data for patients with and without heart disease\n",
    "        st_slope_heart_disease = heart_df[heart_df[\"HeartDisease\"] == 1][column].value_counts()\n",
    "        st_slope_no_heart_disease = heart_df[heart_df[\"HeartDisease\"] == 0][column].value_counts()\n",
    "\n",
    "        # Get the unique ST slope values\n",
    "        st_slope_values = heart_df[column].unique()\n",
    "\n",
    "        # Get the counts for patients with heart disease and without heart disease\n",
    "        y_heart_disease = [st_slope_heart_disease.get(slope, 0) for slope in st_slope_values]\n",
    "        y_no_heart_disease = [st_slope_no_heart_disease.get(slope, 0) for slope in st_slope_values]\n",
    "\n",
    "        # Create the x-axis positions for the bars\n",
    "        x = range(len(st_slope_values))\n",
    "\n",
    "        # Plotting the bar chart for ST_Slope\n",
    "        width = 0.35\n",
    "        plt.bar(x, y_heart_disease, width, label=\"Heart Disease\")\n",
    "        plt.bar([val + width for val in x], y_no_heart_disease, width, label=\"No Heart Disease\")\n",
    "\n",
    "        # Set the x-axis ticks and labels\n",
    "        plt.xticks([val + width/2 for val in x], st_slope_values)\n",
    "\n",
    "    else:\n",
    "        # Plotting the bar chart for other columns\n",
    "        heart_df[column].value_counts().plot(kind='bar')\n",
    "\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Number of Patients\")\n",
    "    plt.title(f\"Comparison of {column} with Heart Disease\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\", \"HeartDisease\", \"FastingBS\"]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    plt.figure()\n",
    "    if column == \"ST_Slope\":\n",
    "        # Filter the data for patients with and without heart disease\n",
    "        st_slope_heart_disease = heart_df.loc[heart_df[\"HeartDisease\"] == 1, column].value_counts()\n",
    "        st_slope_no_heart_disease = heart_df.loc[heart_df[\"HeartDisease\"] == 0, column].value_counts()\n",
    "\n",
    "        # Create a list of all possible ST slope values\n",
    "        st_slope_values = [\"Up\", \"Flat\", \"Down\"]\n",
    "\n",
    "        # Create a list of counts for each ST slope value for patients with heart disease\n",
    "        y_heart_disease = [st_slope_heart_disease.get(slope, 0) for slope in st_slope_values]\n",
    "\n",
    "        # Create a list of counts for each ST slope value for patients without heart disease\n",
    "        y_no_heart_disease = [st_slope_no_heart_disease.get(slope, 0) for slope in st_slope_values]\n",
    "\n",
    "        # Plotting the bar chart for ST_Slope\n",
    "        plt.bar(st_slope_values, y_heart_disease, label=\"Heart Disease\")\n",
    "        plt.bar(st_slope_values, y_no_heart_disease, label=\"No Heart Disease\", bottom=y_heart_disease)\n",
    "    else:\n",
    "        # Plotting the bar chart for other columns\n",
    "        heart_df[column].value_counts().plot(kind='bar')\n",
    "\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Number of Patients\")\n",
    "    plt.title(f\"Comparison of {column} with Heart Disease\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = (heart_df['RestingBP'] == 0).sum()\n",
    "count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = (heart_df['Cholesterol'] == 0).sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median RestingBP value and replace with corresponding median for HeartDisease\n",
    "restingbp_median_by_heartdisease = heart_df.groupby('HeartDisease')['RestingBP'].median()\n",
    "\n",
    "heart_df.loc[heart_df['RestingBP'] == 0, 'RestingBP'] = heart_df.loc[heart_df['RestingBP'] == 0, 'HeartDisease'].map(restingbp_median_by_heartdisease)\n",
    "\n",
    "# Calculate the median Cholesterol value and replace with corresponding median for HeartDisease\n",
    "cholesterol_median_by_heartdisease = heart_df.groupby('HeartDisease')['Cholesterol'].median()\n",
    "\n",
    "heart_df.loc[heart_df['Cholesterol'] == 0, 'Cholesterol'] = heart_df.loc[heart_df['Cholesterol'] == 0, 'HeartDisease'].map(cholesterol_median_by_heartdisease)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = (heart_df['Cholesterol'] == 0).sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categorical_columns = [\"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\", \"HeartDisease\", \"FastingBS\"]\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "heart_df_encoded = heart_df.copy()\n",
    "\n",
    "# Convert categorical columns into dummy variables\n",
    "for column in categorical_columns:\n",
    "    encoded_columns = pd.get_dummies(heart_df_encoded[column], prefix=column, drop_first=True)\n",
    "    heart_df_encoded = pd.concat([heart_df_encoded, encoded_columns], axis=1)\n",
    "\n",
    "# Display the updated DataFrame with dummy variables\n",
    "print(heart_df_encoded.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# Select the categorical columns for correlation heatmap\n",
    "categorical_columns = [\"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\", \"FastingBS\", \"Cholesterol\", \"HeartDisease\",\"Sex\", \"Age\",\"RestingBP\"]\n",
    "\n",
    "# Create a new DataFrame with only the categorical columns\n",
    "categorical_df = heart_df[categorical_columns]\n",
    "\n",
    "# Calculate the Cramer's V statistic matrix\n",
    "corr_matrix = pd.DataFrame(index=categorical_columns, columns=categorical_columns)\n",
    "\n",
    "for col1 in categorical_columns:\n",
    "    for col2 in categorical_columns:\n",
    "        if col1 != col2:\n",
    "            confusion_matrix = pd.crosstab(categorical_df[col1], categorical_df[col2])\n",
    "            chi2 = scipy.stats.chi2_contingency(confusion_matrix)[0]\n",
    "            n = confusion_matrix.sum().sum()\n",
    "            phi2 = chi2 / n\n",
    "            r, k = confusion_matrix.shape\n",
    "            phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "            rc = r - ((r - 1) ** 2) / (n - 1)\n",
    "            kc = k - ((k - 1) ** 2) / (n - 1)\n",
    "            corr_matrix.loc[col1, col2] = np.sqrt(phi2corr / min((kc - 1), (rc - 1)))\n",
    "\n",
    "corr_matrix = corr_matrix.astype(float)\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".3f\")\n",
    "plt.title(\"Categorical Columns Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_ranks = corr_matrix.abs().sum().sort_values(ascending=False)\n",
    "\n",
    "# Print the ranked columns\n",
    "print(\"Ranking of Categorical Columns:\")\n",
    "for rank, column in enumerate(column_ranks.index, start=1):\n",
    "    print(f\"{rank}. {column}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the features and target variable\n",
    "features = heart_df.drop(\"HeartDisease\", axis=1)\n",
    "target = heart_df[\"HeartDisease\"]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_features, val_features, train_target, val_target = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Training set shape:\", train_features.shape, train_target.shape)\n",
    "print(\"Validation set shape:\", val_features.shape, val_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"Age\", \"Sex\", \"ChestPainType\", \"RestingBP\", \"Cholesterol\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "selected_features = [\"Age\", \"Sex\", \"ChestPainType\", \"RestingBP\", \"Cholesterol\"]\n",
    "target = categorical_df[\"HeartDisease\"]\n",
    "k_neighbors = 5  # Number of neighbors, you can experiment with different values\n",
    "\n",
    "train_features_encoded = pd.get_dummies(categorical_df[selected_features])\n",
    "\n",
    "train_features, val_features, train_target, val_target = train_test_split(\n",
    "    train_features_encoded, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "for feature in selected_features:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
    "    knn.fit(train_features, train_target)\n",
    "    val_predictions = knn.predict(val_features)\n",
    "    accuracy = accuracy_score(val_target, val_predictions)\n",
    "    print(f\"Accuracy with feature '{feature}': {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Validation features shape:\", val_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train feature shape:\", train_features[[feature]].shape)\n",
    "print(\"Validation feature shape:\", val_features[[feature]].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with feature 'Age': 59.24%\n",
      "Accuracy with feature 'RestingBP': 57.61%\n",
      "Accuracy with feature 'Cholesterol': 64.67%\n",
      "Accuracy with feature 'Sex_F': 41.85%\n",
      "Accuracy with feature 'Sex_M': 64.13%\n",
      "Accuracy with feature 'ChestPainType_ASY': 80.43%\n",
      "Accuracy with feature 'ChestPainType_ATA': 41.85%\n",
      "Accuracy with feature 'ChestPainType_NAP': 66.30%\n",
      "Accuracy with feature 'ChestPainType_TA': 40.76%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#convert cartegorical features into dummy variables\n",
    "train_features_encoded = pd.get_dummies(train_features)\n",
    "val_features_encoded = pd.get_dummies(val_features)\n",
    "\n",
    "selected_features = [\"Age\", \"Sex\", \"ChestPainType\", \"RestingBP\", \"Cholesterol\"]\n",
    "target = heart_df[\"HeartDisease\"]\n",
    "k_neighbors = 5  # Number of neighbors, you can experiment with different values\n",
    "\n",
    "for feature in train_features_encoded.columns:\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
    "\n",
    "    knn.fit(train_features_encoded[[feature]], train_target)\n",
    "\n",
    "    val_predictions = knn.predict(val_features_encoded[[feature]])\n",
    "\n",
    "    accuracy = accuracy_score(val_target, val_predictions)\n",
    "\n",
    "    accuracy_percentage = accuracy * 100\n",
    "\n",
    "    print(f\"Accuracy with feature '{feature}': {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the accuracy values, it appears that the 'ChestPainType_ASY' feature performed the best \n",
    "# among the selected features, with an accuracy of 0.8043. \n",
    "# It was closely followed by the 'ST_Slope_Up' feature with an accuracy of 0.7989. \n",
    "# These two features seem to have the strongest predictive power in determining the presence of heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the k-NN model with scaled features : 0.76%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_features_scaled = scaler.fit_transform(train_features_encoded)\n",
    "val_features_scaled = scaler.transform(val_features_encoded)\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = k_neighbors)\n",
    "knn_model.fit(train_features_scaled, train_target)\n",
    "val_predictions_scaled = knn_model.predict(val_features_scaled)\n",
    "\n",
    "accuracy_scaled = accuracy_score(val_target, val_predictions_scaled)\n",
    "\n",
    "print(f\"Accuracy of the k-NN model with scaled features : {accuracy_scaled:.2f}%\".format(accuracy_scaled * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_features = train_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling features before training had a positive impact on the model's ability to classify instances correctly. \n",
    "# By considering the scaled features, the model was able to capture more meaningful patterns and achieve higher accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 85.83%\n",
      "Best Parameters: {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Test Acccuracy: 84.78%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "split_percentage = 0.8\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "train_features_encoded = pd.get_dummies(train_features)\n",
    "test_features_encoded = pd.get_dummies(test_features)\n",
    "\n",
    "test_features_encoded = test_features_encoded.reindex(columns=train_features_encoded.columns, fill_value=0)\n",
    "\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    features, target, test_size=1 - split_percentage, random_state=12)\n",
    "\n",
    "scaled_train_features = scaler.fit_transform(train_features_encoded)   \n",
    "scaled_test_features = scaler.transform(test_features_encoded)\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors' : [3,5,7],\n",
    "    'weights': ['uniform','distance'],\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn_model, param_grid, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(scaled_train_features, train_target)\n",
    "test_predictions = grid_search.best_estimator_.predict(scaled_test_features)\n",
    "\n",
    "test_accuracy = accuracy_score(test_target, test_predictions)\n",
    "\n",
    "print(\"Best Score: {:.2%}\".format(grid_search.best_score_))\n",
    "print(\"Best Parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Test Acccuracy: {:.2%}\".format(test_accuracy))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_target shape: (184,)\n",
      "test_predictions shape: (184,)\n"
     ]
    }
   ],
   "source": [
    "print(\"test_target shape:\", test_target.shape)\n",
    "print(\"test_predictions shape:\", test_predictions.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random_state = 42 - Best Score: 86.37%, Best Parameters: {'n_neighbors': 7, 'weights': 'uniform'},Test Acccuracy: 83.70%\n",
    "# random_state = 52 Best Score: 84.33%, Best Parameters: {'n_neighbors': 7, 'weights': 'uniform'},Test Acccuracy: 86.96%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 54.50%\n",
      "Best Parameters: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Test Accuracy: 51.63%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#split the dataset into training and test sets\n",
    "split_percentage = 0.8\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_features_encoded = pd.get_dummies(train_features)\n",
    "test_features_encoded = pd.get_dummies(test_features)\n",
    "\n",
    "test_features_encoded = test_features_encoded.reindex(columns=train_features_encoded.columns, fill_value=0)\n",
    "\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    features, target, test_size=1 - split_percentage, random_state=42)\n",
    "\n",
    "scaled_train_features = scaler.fit_transform(train_features_encoded)   \n",
    "scaled_test_features = scaler.transform(test_features_encoded)\n",
    "\n",
    "#create a dictionary that stores the parameters and values you want to earch over as key-value pairs\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn_model, param_grid, scoring='accuracy')\n",
    "grid_search.fit(scaled_train_features, train_target)\n",
    "\n",
    "test_predictions = grid_search.best_estimator_.predict(scaled_test_features)\n",
    "test_accuracy = accuracy_score(test_target, test_predictions)\n",
    "\n",
    "print(\"Best Score: {:.2%}\".format(grid_search.best_score_))\n",
    "print(\"Best Parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Test Accuracy: {:.2%}\".format(test_accuracy))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There could be several reasons why the test set accuracy is higher:\n",
    "# Randomness, Data mismatch: If the training and test sets have significant differences in their distributions or characteristics, Overfitting: It's possible that the model is overfitting the training data\n",
    "# Potential improvements to performance:Feature engineering, Hyperparameter tuning, More data, Regularization, Ensemble methods.\n",
    "<!-- Pros and cons of using this model in a real-world healthcare setting:\n",
    "Pros:\n",
    "KNN can handle both numerical and categorical features, making it versatile for healthcare data that often contains a mix of both types.\n",
    "It can capture complex non-linear relationships between features and the target variable.\n",
    "KNN does not make assumptions about the underlying data distribution.\n",
    "Cons:\n",
    "It requires careful selection of the value for K, the number of neighbors, which can impact model performance.\n",
    "KNN is sensitive to the scale of features, so feature scaling is necessary for accurate results.\n",
    "It may not perform well when dealing with imbalanced datasets or noisy data.\n",
    "#\n",
    "# -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data\n",
    "original_data_sex = heart_df['Sex'].value_counts()\n",
    "\n",
    "# Train data\n",
    "train_data_sex = train_features['Sex'].value_counts()\n",
    "\n",
    "# Test data\n",
    "test_data_sex = test_features['Sex'].value_counts()\n",
    "\n",
    "print(\"Original data - Sex:\\n\", original_data_sex)\n",
    "print(\"Train data - Sex:\\n\", train_data_sex)\n",
    "print(\"Test data - Sex:\\n\", test_data_sex)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
